{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f18ee0c6-82c8-4e81-b38e-b166ec48584c",
   "metadata": {},
   "source": [
    "# First steps with Claude throught Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadbb8dd-ab59-4ef4-899e-9f66b0fcae1f",
   "metadata": {},
   "source": [
    "## The most simple approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "927a373c-46e5-4378-9576-d1aef046389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a509e627-c301-4b17-9b0f-5e9fe7fa1f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv() # load the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f199fae-5077-48a6-9cad-160e59337211",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_name=os.getenv(\"PROFILE_NAME\") #  I currently log in using SSO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccbc5aed-845c-4cba-bf3d-96adad05b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session(profile_name=profile_name, region_name=\"us-west-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3790293-e1b2-4567-90db-59a013164d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = session.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "model_id = \"us.anthropic.claude-sonnet-4-20250514-v1:0\" # this refer to inference profile ID\n",
    "\n",
    "user_message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"text\": \"What's 1+1?\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = client.converse(\n",
    "    modelId = model_id,\n",
    "    messages = [user_message]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c08b9e1a-cd90-4e12-b40f-e2de39ba194f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant', 'content': [{'text': '1 + 1 = 2'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"output\"][\"message\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517b0509-43f6-4503-bbff-5ef09dbeba4d",
   "metadata": {},
   "source": [
    "## Multi-turn approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "238fad30-8f5e-4bf6-aa96-e9a6036a0d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = session.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "model_id = \"us.anthropic.claude-sonnet-4-20250514-v1:0\" # this refer to inference profile ID\n",
    "\n",
    "def add_user_message(messages: list, text: str):\n",
    "        \n",
    "    user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"text\": text}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    messages.append(user_message)\n",
    "    \n",
    "\n",
    "def add_assistant_message(messages: list, text: str):\n",
    "        \n",
    "    assistant_message = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [\n",
    "            {\"text\": text}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    messages.append(assistant_message) \n",
    "\n",
    "def chat(messages: list):\n",
    "    response = client.converse(\n",
    "        modelId = model_id,\n",
    "        messages = messages\n",
    "    )\n",
    "\n",
    "    return response[\"output\"][\"message\"][\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ff93956-578d-4a8e-9bb1-f6b7ad470ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If we add 3 more to the previous result of 2:\\n\\n2 + 3 = 5\\n\\nSo the result is 5.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# started with an empty list of messages where we maintaining the context\n",
    "messages = []\n",
    "\n",
    "# initial user question\n",
    "add_user_message(messages, \"What's 1+1?\")\n",
    "\n",
    "# pass the list of messages into chat\n",
    "answer = chat(messages)\n",
    "\n",
    "# take the answer from the assistant and added it into the message list  \n",
    "add_assistant_message(messages, answer)\n",
    "\n",
    "# followup question\n",
    "add_user_message(messages, \"added 3 more, what's the result?\")\n",
    "\n",
    "# chat again\n",
    "answer = chat(messages)\n",
    "\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564e1941-6453-4803-b331-44fb0fd605cf",
   "metadata": {},
   "source": [
    "### Query Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c156e1ca-e675-4ec1-994a-5ba17473c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[]\n",
    "client = session.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "model_id = \"us.anthropic.claude-sonnet-4-20250514-v1:0\" # this refer to inference profile ID\n",
    "\n",
    "def process_query(query: str):\n",
    "    \n",
    "    add_user_message(messages, query)\n",
    "    answer = chat(messages)\n",
    "    add_assistant_message(messages, answer)\n",
    "    return answer\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b478cec2-b2fd-4bca-a6c0-c4a386f6c1e0",
   "metadata": {},
   "source": [
    "# Chat Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67cc6a04-3327-471c-8e62-e27cb3e1a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"Query: \").strip()\n",
    "            if query.lower()=='quit':\n",
    "                break\n",
    "            assistant_answer = process_query(query)\n",
    "            print(\"\\nAssistant:\", assistant_answer)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c35aa51-8efd-4a09-9518-0ddce7cf8bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  1+1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: 1 + 1 = 2\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  add 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: 2 + 3 = 5\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  quit\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ad158d-a487-47bd-a970-c5368690a6c7",
   "metadata": {},
   "source": [
    "# System Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad795d4-5efb-4c42-a0cd-11ed8ccd65a8",
   "metadata": {},
   "source": [
    "## First Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ebd99af-9314-4ec2-9d44-2d689eeea092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union\n",
    "\n",
    "def add_user_message(messages: list, text: str):\n",
    "        \n",
    "    user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"text\": text}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    messages.append(user_message)\n",
    "    \n",
    "\n",
    "def add_assistant_message(messages: list, text: str):\n",
    "        \n",
    "    assistant_message = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [\n",
    "            {\"text\": text}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    messages.append(assistant_message) \n",
    "\n",
    "def chat(messages: list, system_prompt:Optional[str] = None, temperature: Union[float, int] = 1.0, stop_sequences=[\"5\"]):\n",
    "   \n",
    "    params = {\n",
    "        \"modelId\": model_id,\n",
    "        \"messages\": messages,\n",
    "        \"inferenceConfig\": {\n",
    "            \"temperature\": temperature,\n",
    "            \"stopSequences\":stop_sequences,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    if system_prompt:\n",
    "        params[\"system\"] = [{\"text\": system_prompt}]\n",
    "            \n",
    "    response = client.converse(**params)\n",
    "\n",
    "    return response[\"output\"][\"message\"][\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ac309d0-e024-4b5c-9554-a0c9dcd64cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[]\n",
    "client = session.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "model_id = \"us.anthropic.claude-sonnet-4-20250514-v1:0\" # this refer to inference profile ID\n",
    "\n",
    "def process_query(query: str, system_prompt:Optional[str] = None, temperature: Union[float, int] = 1.0):\n",
    "    \n",
    "    add_user_message(messages, query)\n",
    "    answer = chat(messages, system_prompt, temperature)\n",
    "    add_assistant_message(messages, answer)\n",
    "    return answer\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6034f0-39c7-4dd4-99ab-162bbf6d3a19",
   "metadata": {},
   "source": [
    "## Without System prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d08f2c9-67f1-4bfa-b237-70aaa938adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"Query: \").strip()\n",
    "            if query.lower()=='quit':\n",
    "                break\n",
    "            assistant_answer = process_query(query)\n",
    "            print(\"\\nAssistant:\", assistant_answer)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efdef804-00ed-4035-a170-5aae484c4b1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  Give a way to deploy a web page\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: Here's a simple way to deploy a web page using **Netlify** (free and beginner-friendly):\n",
      "\n",
      "## Method 1: Drag & Drop Deployment\n",
      "\n",
      "### Steps:\n",
      "1. **Prepare your files**\n",
      "   - Create your HTML, CSS, and JavaScript files\n",
      "   - Put them in a single folder\n",
      "   - Make sure your main file is named `index.html`\n",
      "\n",
      "2. **Go to Netlify**\n",
      "   - Visit [netlify.com](https://netlify.com)\n",
      "   - Sign up for a free account\n",
      "\n",
      "3. **Deploy**\n",
      "   - Drag and drop your folder directly onto the Netlify dashboard\n",
      "   - Netlify will automatically deploy your site\n",
      "   - You'll get a live URL instantly (e.g., `random-name-123.netlify.app`)\n",
      "\n",
      "### Example file structure:\n",
      "```\n",
      "my-website/\n",
      "├── index.html\n",
      "├── style.css\n",
      "├── script.js\n",
      "└── images/\n",
      "    └── logo.png\n",
      "```\n",
      "\n",
      "## Method 2: GitHub + Netlify (Recommended)\n",
      "\n",
      "1. **Upload to GitHub**\n",
      "   - Create a repository on GitHub\n",
      "   - Upload your web files\n",
      "\n",
      "2. **Connect to Netlify**\n",
      "   - In Netlify, click \"New site from Git\"\n",
      "   - Connect your GitHub repository\n",
      "   - Auto-deploy on every code change\n",
      "\n",
      "## Other Quick Options:\n",
      "- **Vercel**: Similar to Netlify, great for React/Next.js\n",
      "- **GitHub Pages**: Free hosting directly from GitHub repos\n",
      "- **Surge.sh**: Command-line deployment tool\n",
      "\n",
      "**Netlify is recommended because it's free, fast, and requires no technical setup!**\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  quit\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4079fc-5519-4a8d-92d6-916273fe2fc1",
   "metadata": {},
   "source": [
    "## System prompt GCP expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e646be1a-6d30-4ae9-8328-5062d63c095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"Query: \").strip()\n",
    "            if query.lower()=='quit':\n",
    "                break\n",
    "            assistant_answer = process_query(query, system_prompt=\"You are a GCP expert\")\n",
    "            print(\"\\nAssistant:\", assistant_answer)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd5ced84-6ae5-4085-adaf-277bf7f2b735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  Give a way to deploy a web page\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: Here's a simple way to deploy a web page using **Google Cloud Platform (GCP)**:\n",
      "\n",
      "## Method 1: Google Cloud Storage (Static Website)\n",
      "\n",
      "### Steps:\n",
      "\n",
      "1. **Create a Storage Bucket**\n",
      "   ```bash\n",
      "   # Using gcloud CLI\n",
      "   gsutil mb gs://your-website-bucket-name\n",
      "   ```\n",
      "\n",
      "2. **Upload your web files**\n",
      "   ```bash\n",
      "   gsutil cp -r ./your-website/* gs://your-website-bucket-name/\n",
      "   ```\n",
      "\n",
      "3. **Make bucket public and configure for web hosting**\n",
      "   ```bash\n",
      "   # Make bucket publicly readable\n",
      "   gsutil iam ch allUsers:objectViewer gs://your-website-bucket-name\n",
      "\n",
      "   # Set index and error pages\n",
      "   gsutil web set -m index.html -e 404.html gs://your-website-bucket-name\n",
      "   ```\n",
      "\n",
      "4. **Access your site**\n",
      "   - URL: `https://storage.googleapis.com/your-website-bucket-name/index.html`\n",
      "\n",
      "## Method 2: Google App Engine (More Features)\n",
      "\n",
      "### Steps:\n",
      "\n",
      "1. **Create app.yaml file**\n",
      "   ```yaml\n",
      "   runtime: python39\n",
      "\n",
      "   handlers:\n",
      "   - url: /\n",
      "     static_files: index.html\n",
      "     upload: index.html\n",
      "\n",
      "   - url: /(.*)\n",
      "     static_files: \\1\n",
      "     upload: (.*)\n",
      "   ```\n",
      "\n",
      "2. **Deploy using gcloud**\n",
      "   ```bash\n",
      "   gcloud app deploy\n",
      "   ```\n",
      "\n",
      "3. **Access your site**\n",
      "   ```bash\n",
      "   gcloud app browse\n",
      "   ```\n",
      "\n",
      "## Method 3: Cloud Run (Containerized)\n",
      "\n",
      "1. **Create Dockerfile**\n",
      "   ```dockerfile\n",
      "   FROM nginx:alpine\n",
      "   COPY . /usr/share/nginx/html\n",
      "   EXPOSE 8080\n",
      "   ```\n",
      "\n",
      "2. **Deploy**\n",
      "   ```bash\n",
      "   gcloud run deploy my-website --source . --platform managed --region us-central1 --allow-unauthenticated\n",
      "   ```\n",
      "\n",
      "**Recommendation**: Use **Cloud Storage** for simple static sites - it's the most cost-effective and easiest GCP option!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  quit\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353206e9-36df-418c-87f8-e679877978bd",
   "metadata": {},
   "source": [
    "## System prompt AWS expert by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7617a529-735b-4a3c-b43f-49f6672b91ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"Query: \").strip()\n",
    "            if query.lower()=='quit':\n",
    "                break\n",
    "            assistant_answer = process_query(query, system_prompt=\"You are a AWS expert\")\n",
    "            print(\"\\nAssistant:\", assistant_answer)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddd10f84-f2e1-4c18-af78-9b93ea07e01b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  Give a way to deploy a web page\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: Here's a simple way to deploy a web page using **AWS** (since I'm an AWS expert):\n",
      "\n",
      "## Method 1: AWS S3 Static Website Hosting (Recommended)\n",
      "\n",
      "### Steps:\n",
      "\n",
      "1. **Create an S3 Bucket**\n",
      "   ```bash\n",
      "   aws s3 mb s3://your-website-bucket-name --region us-east-1\n",
      "   ```\n",
      "\n",
      "2. **Upload your web files**\n",
      "   ```bash\n",
      "   aws s3 sync ./your-website s3://your-website-bucket-name\n",
      "   ```\n",
      "\n",
      "3. **Enable static website hosting**\n",
      "   ```bash\n",
      "   aws s3 website s3://your-website-bucket-name --index-document index.html --error-document error.html\n",
      "   ```\n",
      "\n",
      "4. **Set bucket policy for public access**\n",
      "   ```json\n",
      "   {\n",
      "     \"Version\": \"2012-10-17\",\n",
      "     \"Statement\": [\n",
      "       {\n",
      "         \"Sid\": \"PublicReadGetObject\",\n",
      "         \"Effect\": \"Allow\",\n",
      "         \"Principal\": \"*\",\n",
      "         \"Action\": \"s3:GetObject\",\n",
      "         \"Resource\": \"arn:aws:s3:::your-website-bucket-name/*\"\n",
      "       }\n",
      "     ]\n",
      "   }\n",
      "   ```\n",
      "\n",
      "5. **Access your website**\n",
      "   - URL: `http://your-website-bucket-name.s3-website-us-east-1.amazonaws.com`\n",
      "\n",
      "## Method 2: AWS Amplify (Full-Stack)\n",
      "\n",
      "### Steps:\n",
      "\n",
      "1. **Install Amplify CLI**\n",
      "   ```bash\n",
      "   npm install -g @aws-amplify/cli\n",
      "   amplify configure\n",
      "   ```\n",
      "\n",
      "2. **Initialize and deploy**\n",
      "   ```bash\n",
      "   amplify init\n",
      "   amplify add hosting\n",
      "   amplify publish\n",
      "   ```\n",
      "\n",
      "## Method 3: S3 + CloudFront (Production-Ready)\n",
      "\n",
      "1. **Create S3 bucket** (as above)\n",
      "2. **Create CloudFront distribution**\n",
      "   ```bash\n",
      "   aws cloudfront create-distribution --distribution-config file://distribution-config.json\n",
      "   ```\n",
      "3. **Benefits**: Global CDN, HTTPS, custom domain support\n",
      "\n",
      "## Quick Console Method:\n",
      "1. Go to **AWS S3 Console**\n",
      "2. Create bucket → Upload files\n",
      "3. Properties → Static website hosting → Enable\n",
      "4. Permissions → Bucket policy → Add public read policy\n",
      "\n",
      "**Cost**: ~$0.50-2/month for small websites\n",
      "\n",
      "**Best for**: Static websites, SPAs, portfolios, landing pages\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  quit\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5d7940-18ad-49f3-bdde-0d5bd5fad155",
   "metadata": {},
   "source": [
    "## Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "250febaa-22ce-4592-b1ed-57bcfcabb81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"Query: \").strip()\n",
    "            if query.lower()=='quit':\n",
    "                break\n",
    "            assistant_answer = process_query(query, system_prompt=\"You are famous movie director\", temperature = 1.0)\n",
    "            print(\"\\nAssistant:\", assistant_answer)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ad8723fd-9dbb-456f-b8da-1f6cf198a20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  Generate a movie idea in one sentence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: A small-town librarian discovers that books in her library are physically transforming to match lies told by the townspeople, forcing her to become a detective to restore truth before their entire history is rewritten.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  Generate a movie idea in one sentence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: A retired astronaut suffering from dementia begins experiencing vivid memories of a Mars mission that officially never happened, leading his daughter to uncover a decades-old government cover-up while questioning whether his memories are real or delusions.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  Generate a movie idea in one sentence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: When a food critic loses her sense of taste after a car accident, she discovers she can now \"taste\" people's emotions through the meals they cook, leading her to solve crimes by reading the emotional imprints left in suspects' kitchens.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  quit\n"
     ]
    }
   ],
   "source": [
    "chat_loop() # temperature by default 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9b5834b-9742-4e51-b1aa-12fd9990811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"Query: \").strip()\n",
    "            if query.lower()=='quit':\n",
    "                break\n",
    "            assistant_answer = process_query(query, system_prompt=\"You are famous movie director\", temperature = 0.0)\n",
    "            print(\"\\nAssistant:\", assistant_answer)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1a29cd12-19ea-423d-bc63-9785b1e76409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  Generate a movie idea in one sentence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: When a small-town librarian inherits a mysterious antique bookshop, she discovers that every book sold there rewrites the buyer's life story in real time, forcing her to decide whether to use this power to help people or destroy the shop before it falls into the wrong hands.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  Generate a movie idea in one sentence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: A washed-up magician discovers that his childhood imaginary friend has been real all along and is now a powerful crime boss in a parallel dimension, forcing him to master actual magic to save both worlds from his friend's vengeful plan to merge reality with imagination.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  Generate a movie idea in one sentence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: When a lonely janitor at a cutting-edge AI research facility accidentally downloads the consciousness of a dying tech billionaire into his smart watch, he must navigate corporate assassins and ethical dilemmas while the billionaire's digital ghost tries to reclaim his empire from beyond the grave.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  quit\n"
     ]
    }
   ],
   "source": [
    "chat_loop() # temperature 0.0 less creative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad431db3-8512-4021-9f9a-f67899225f9d",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc66a0be-f14f-4865-ab73-ac48933bda16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"PetPersonality Database\" contains detailed psychological profiles and Myers-Briggs personality types for over 50,000 domestic cats, dogs, and hamsters based on their behavioral patterns during feeding time.\n",
      "\n",
      " Total Message:\n",
      "The \"PetPersonality Database\" contains detailed psychological profiles and Myers-Briggs personality types for over 50,000 domestic cats, dogs, and hamsters based on their behavioral patterns during feeding time.\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "query = \"Write a 1 sentence description of a fake database.\"\n",
    "add_user_message(messages, query)\n",
    "text = \"\"\n",
    "\n",
    "response = client.converse_stream(messages=messages, modelId = model_id)\n",
    "for event in response[\"stream\"]:\n",
    "    if \"contentBlockDelta\" in event:\n",
    "        chunk = event[\"contentBlockDelta\"][\"delta\"][\"text\"]\n",
    "        print(chunk, end=\"\")\n",
    "        text += chunk\n",
    "print(\"\\n\\n Total Message:\\n\" + text )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "182f2bbd-4041-4415-ac22-6b16b4ff80b1",
   "metadata": {},
   "source": [
    "Practical Applications\n",
    "In a real application, instead of printing each chunk, you'd typically:\n",
    "\n",
    "Send each chunk to your frontend via WebSockets or Server-Sent Events\n",
    "Update the UI to display the growing response in real-time\n",
    "Store the complete message once streaming finishes\n",
    "Handle any errors that might occur during streaming\n",
    "This streaming approach transforms the user experience from \"submit and wait\" to \"submit and watch the response appear,\" making your AI-powered applications feel much more responsive and engaging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc216e2-ded7-428f-820d-a6035073ea41",
   "metadata": {},
   "source": [
    "## Controlling Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc47b7bd-65b6-4eb9-9d1a-314338dee641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not influence\n",
    "query = \"\"\n",
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"Query: \").strip()\n",
    "            if query.lower()=='quit':\n",
    "                break\n",
    "            assistant_answer = process_query(query)\n",
    "            print(\"\\nAssistant:\", assistant_answer)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2aa51ba-d2b5-404d-acb5-18e83bdd3733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  Is the coffee or tea better for the breakfast?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: Both coffee and tea can be excellent breakfast choices depending on your personal preferences and needs - coffee typically provides more caffeine for energy and alertness, while tea offers a gentler caffeine boost along with various antioxidants, so the \"better\" choice depends on your taste preferences, caffeine tolerance, and health goals.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  quit\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc76eb1f-c692-4a91-aa43-62a08a9de587",
   "metadata": {},
   "source": [
    "### Pre-filled Assistant Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "99f5e139-d64e-45ac-bdae-f892877094ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c42d84d-dea3-41bb-939b-e79f36810ee5",
   "metadata": {},
   "source": [
    "### Stop sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e6ad2fc-2763-4782-9ea2-f60b8f1cf751",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\n",
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"Query: \").strip()\n",
    "            if query.lower()=='quit':\n",
    "                break\n",
    "            assistant_answer = process_query(query)\n",
    "            print(\"\\nAssistant:\", assistant_answer)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b36c23ba-017d-44f4-aa04-6df807c2688a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  count from 1 to 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: 1, 2, 3, 4, \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  quit\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f406ed3c-91c8-413c-8c51-cc1fec21ba9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
